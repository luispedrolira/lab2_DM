---
title: "Laboratorio 2"
author: "Luis Pedro Lira 23669, Mario Rocha 23501, Juan Francisco Martínez 23617"
date: "2025-02-07"
output:
  pdf_document:
    latex_engine: xelatex
editor_options:
  markdown:
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,      # no muestra código
  message = FALSE,   # no muestra mensajes
  warning = FALSE    # no muestra warnings
)
```



```{r paquetes y datos, message=FALSE, warning=FALSE}

library(psych)
library(FactoMineR)
library(corrplot)
library(fpc)
library(factoextra)
library(PCAmixdata)
library(paran)
library(dplyr)
library(tidyverse)
library(janitor)
library(lubridate)
library(skimr)
library(clustertend)
library(cluster)

datos <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)
```


###Análisis de Componentes Principales (PCA)

###3.1 Selección de Variables y Preprocesamiento

```{r include = FALSE}
# Selección de variables numéricas
vars_pca <- datos %>%
  select(popularity,
         budget,
         revenue,
         runtime,
         voteCount,
         voteAvg,
         actorsPopularity,
         actorsAmount,
         castWomenAmount,
         castMenAmount,
         genresAmount,
         productionCoAmount,
         productionCountriesAmount,
         releaseYear)

# Reemplazar strings vacíos por NA
vars_pca[vars_pca == ""] <- NA

# Convertir todo a numérico de forma segura
vars_pca <- data.frame(lapply(vars_pca, function(x) as.numeric(as.character(x))))

# Eliminar filas con NA
vars_pca <- na.omit(vars_pca)

# Verificar que todo sea numérico
str(vars_pca)

# Escalar
vars_scaled <- scale(vars_pca)
```

###3.2 Matriz de Correlación
```{r}
cor_matrix <- cor(vars_scaled)
corrplot(cor_matrix, method = "color")
```
En la matriz de correlación se observan asociaciones importantes entre varias variables del conjunto de datos. Destaca una correlación positiva entre budget y revenue, lo cual es consistente con la lógica de la industria cinematográfica: producciones con mayor presupuesto tienden a generar mayores ingresos.

También se observa relación entre voteCount, popularity y actorsPopularity, lo que sugiere que películas con mayor visibilidad tienden a recibir más votos.

Asimismo, existe alta correlación entre actorsAmount, castMenAmount y castWomenAmount, lo cual es esperado debido a que representan componentes del tamaño total del elenco.

Estas correlaciones evidencian redundancia entre variables, lo que justifica la aplicación del Análisis de Componentes Principales para reducir la dimensionalidad del conjunto de datos.




###3.3 Medida de Adecuación Muestral (Índice KMO)
```{r results='hide'}
KMO(vars_scaled)
```

El índice KMO global obtenido fue de 0.69, lo cual indica una adecuación muestral aceptable para aplicar el Análisis de Componentes Principales.

Según la clasificación de Kaiser:
	•	0.90 → Excelente
	•	0.80 → Muy bueno
	•	0.70 → Bueno
	•	0.60 → Aceptable
	•	<0.50 → Inadecuado

En este caso, el valor se encuentra cercano a 0.70, lo que sugiere que las correlaciones parciales entre variables no son excesivamente altas y que el análisis factorial es apropiado, aunque no óptimo.





###3.4 Prueba de Esfericidad de Bartlett
```{r}
cortest.bartlett(cor_matrix, n = nrow(vars_scaled))
```
La prueba de esfericidad de Bartlett resultó altamente significativa ($\chi^2 = 5416.44$ p < 0.001), lo que permite rechazar la hipótesis nula de que la matriz de correlación es una matriz identidad.

Esto confirma que existe correlación suficiente entre las variables y que el Análisis de Componentes Principales es apropiado para este conjunto de datos.



###3.5 Aplicación del Análisis de Componentes Principales
```{r }
pca_model <- prcomp(vars_scaled, center = TRUE, scale. = TRUE)

summary(pca_model)
```


##3.6 Determinación del Número de Componentes (Scree Plot y Varianza Explicada)
```{r}
fviz_eig(pca_model, addlabels = TRUE)
```

```{r}
eigenvalues <- pca_model$sdev^2
eigenvalues
```
El primer componente principal explica el 24.3% de la variabilidad total, seguido por el segundo con 12.6% y el tercero con 10.2%.

El gráfico de sedimentación muestra una disminución pronunciada después del tercer componente y una estabilización progresiva a partir del quinto componente.

Se decidió conservar los primeros 7 componentes, ya que explican aproximadamente el 74.7% de la variabilidad total, lo cual representa una reducción considerable de dimensionalidad manteniendo una proporción adecuada de información.




###3.7 Interpretación de los Componentes Principales
```{r}
loadings <- pca_model$rotation
round(loadings, 3)
```
```{r}
fviz_pca_biplot(pca_model, 
                repel = TRUE,
                col.var = "red",
                col.ind = "gray")
```
El primer componente parece representar una dimensión de impacto y visibilidad comercial, ya que agrupa variables relacionadas con popularidad, número de votos y popularidad del elenco.

La carga negativa en releaseYear sugiere que películas más antiguas tienden a tener mayor acumulación de popularidad y votos, lo cual puede deberse a mayor tiempo en el mercado.




###3.8 Conclusiones del PCA


El Análisis de Componentes Principales permitió reducir la dimensionalidad del conjunto de datos original compuesto por 14 variables numéricas, sintetizando la información en un menor número de componentes sin perder una proporción significativa de variabilidad.

Los primeros 7 componentes explican aproximadamente el 74.7% de la variabilidad total, lo cual representa una reducción considerable de la complejidad del dataset manteniendo la mayor parte de la información relevante.

El primer componente principal se asocia principalmente con variables relacionadas con popularidad, número de votos y popularidad del elenco, por lo que puede interpretarse como una dimensión de impacto y desempeño comercial.

El segundo componente está vinculado con la composición del elenco, diferenciando películas según la cantidad y distribución de actores.

El tercer componente refleja características estructurales de producción, como el número de compañías productoras y países involucrados, lo cual sugiere distintos niveles de complejidad en las producciones cinematográficas.

En conjunto, el PCA revela que las películas pueden caracterizarse principalmente a través de tres grandes dimensiones: impacto comercial, estructura del elenco y complejidad de producción.

Estos resultados son útiles para CineVision Studios, ya que permiten comprender cuáles factores explican mayor variabilidad en el mercado cinematográfico y pueden servir como base para futuros modelos predictivos o segmentaciones estratégicas.





```{r Seleccion de variables}}
# 1) Variables  NO útiles para formar grupos (IDs / texto libre / URLs / listas enormes):
vars_drop_if_exist <- c(
  "id", "original_title", "title", "homepage",
  "director", "actors", "actors_character",
  "production_company", "production_company_country",
  "production_country", "release_date"
)

df <- datos |> select(-any_of(vars_drop_if_exist))

# 2) Define  variables numéricas para calcular los grupos 
vars_num_raw <- c(
  "popularity", "budget", "revenue", "runtime",
  "vote_count", "vote_avg", "actors_popularity",
  "genres_amount", "production_co_amount", "production_countries_amount",
  "actors_amount", "cast_women_amount", "cast_men_amount",
  "release_year"
)

# Qué variables de esas realmente existen 
vars_num <- intersect(vars_num_raw, names(df))
vars_missing <- setdiff(vars_num_raw, names(df))

cat("Numéricas usadas para clustering:\n")
print(vars_num)
cat("\nNuméricas NO encontradas (si esperabas verlas, revisa nombres):\n")
print(vars_missing)

stopifnot(length(vars_num) >= 4)

df_num <- df |> select(all_of(vars_num))

# Asegurar numéricas 
df_num <- df_num |> mutate(across(everything(), ~ suppressWarnings(as.numeric(.x))))

# Imputación simple
impute_median <- function(x){
  ifelse(is.na(x), median(x, na.rm = TRUE), x)
}
df_num_imp <- df_num |> mutate(across(everything(), impute_median))

# Transformaciones para colas largas 
vars_log1p <- intersect(c("budget", "revenue", "vote_count", "popularity", "actors_popularity"), vars_num)
df_num_tr <- df_num_imp |> mutate(across(all_of(vars_log1p), ~ log1p(pmax(.x, 0))))

# Estandarización (k-means y distancias lo necesitan)
X <- scale(df_num_tr)
X <- as.matrix(X)

cat("Dimensiones de X (filas, columnas):\n")
print(dim(X))
```
Para construir los grupos se trabajó únicamente con variables numéricas que describen magnitud y desempeño de una película. Se excluyeron variables de tipo identificador o texto porque no representan distancias comparables en el espacio numérico y pueden introducir ruido. Luego se realizó limpieza básica: se convirtieron cadenas vacías a NA, se forzó conversión segura a numérico y se imputaron faltantes con la mediana por variable para evitar perder demasiadas filas. Debido a que variables como presupuesto/ingresos/votos suelen tener colas largas, se aplicó log1p() para reducir asimetría y estabilizar distancias. Finalmente, se estandarizaron todas las variables para que ninguna domine el agrupamiento solo por estar en otra escala .

```{r Hopkins}

set.seed(123)

idx_tend <- sample(seq_len(nrow(X)), min(3000, nrow(X)))
X_tend <- X[idx_tend, , drop = FALSE]
n_tend <- min(200, floor(0.1 * nrow(X_tend)))

tend <- factoextra::get_clust_tendency(X_tend, n = n_tend, graph = TRUE)
tend$hopkins_stat   # Hopkins
tend$plot           # VAT (imagen de disimilitud ordenada)
```
Con Hopkins = 0.9568, la evidencia de tendencia a formar clusters es muy fuerte: un valor cercano a 1 indica que las distancias entre puntos no se comportan como si fueran aleatorias, sino que hay agrupamientos reales

El VAT refuerza esa conclusión visualmente. En el mapa se observan bloques relativamente definidos separados por transiciones más claras, lo que suele interpretarse como la presencia de varios grupos con alta similitud interna y mayor disimilitud con otros grupos. 

```{r Grafica de Codo}
k_max <- 12

# Codo (WSS) 
factoextra::fviz_nbclust(X, kmeans, method = "wss", k.max = k_max) +
  ggtitle("Método del codo (WSS)")

# (Opcional pero útil) Silhouette vs k para apoyar tu decisión
factoextra::fviz_nbclust(X[sample(nrow(X), min(3000, nrow(X))), ], kmeans,
                         method = "silhouette", k.max = k_max) +
  ggtitle(" Silhouette promedio vs k (muestra)")
```

```{r Elegir el K}
# Para que el flujo sea "óptimo" sin adivinar, elegimos k por silhouette promedio en muestra
# (y en el reporte justificas con el codo + esta evidencia).
n_k <- min(4000, nrow(X))
idx_k <- sample(seq_len(nrow(X)), n_k)
X_k <- X[idx_k, , drop = FALSE]

avg_sil_by_k <- function(k){
  km <- kmeans(X_k, centers = k, nstart = 30, iter.max = 100)
  d  <- dist(X_k)
  sil <- cluster::silhouette(km$cluster, d)
  mean(sil[, 3])
}

ks <- 2:k_max
sil_vals <- sapply(ks, avg_sil_by_k)

sil_tbl <- tibble(k = ks, avg_silhouette = sil_vals)
sil_tbl |> arrange(desc(avg_silhouette)) |> head(10)

k_star <- sil_tbl |> arrange(desc(avg_silhouette)) |> slice(1) |> pull(k)
cat("k elegido (por silhouette en muestra):", k_star, "\n")
```
Con el método del codo  se observa una caída muy pronunciada de la variabilidad intra-cluster al pasar de k=1 → 2 → 3 y aún una mejora relevante hasta alrededor de k≈5; a partir de ahí la curva entra en una zona de rendimientos decrecientes, donde aumentar k reduce el WSS solo de forma marginal y la línea se vuelve mucho más “plana”. Sin embargo, al contrastar esa evidencia con la silueta promedio, el mejor valor se obtiene en k=7 con 0.635, ligeramente superior a k=6 (0.631) y claramente por encima de k=5 (0.590). Por eso se elige k=7: aunque el codo sugiere que desde ~5 ya no hay mejoras enormes, k=7 ofrece el mejor balance entre cohesión interna y separación entre grupos sin caer en una fragmentación excesiva, y además coincide con una zona donde el WSS ya está cerca del “plateau” .
```{r Agrupamiento}
# K-means en TODO el dataset
km_fit <- kmeans(X, centers = k_star, nstart = 50, iter.max = 200)

df_km <- df |> mutate(cluster_kmeans = factor(km_fit$cluster))

# Jerárquico: por complejidad O(n^2), lo hacemos en muestra (suficiente para comparar estructura)
n_hc <- min(3000, nrow(X))
idx_hc <- sample(seq_len(nrow(X)), n_hc)
X_hc <- X[idx_hc, , drop = FALSE]

d_hc <- dist(X_hc)
hc_fit <- hclust(d_hc, method = "ward.D2")
hc_clusters <- cutree(hc_fit, k = k_star)

df_hc <- df[idx_hc, ] |> mutate(cluster_hc = factor(hc_clusters))

# Dendrograma (opcional, puede ser grande)
plot(hc_fit, labels = FALSE, main = "Clustering jerárquico (Ward.D2) - muestra")
rect.hclust(hc_fit, k = k_star, border = 2:6)
```

```{r Silueta}
# Silueta kmeans (en la muestra jerárquica para comparar apples-to-apples)
km_sample_clusters <- km_fit$cluster[idx_hc]
sil_km <- cluster::silhouette(km_sample_clusters, d_hc)
avg_sil_km <- mean(sil_km[, 3])

# Silueta jerárquico (en la misma muestra)
sil_hc <- cluster::silhouette(hc_clusters, d_hc)
avg_sil_hc <- mean(sil_hc[, 3])

cat("Silhouette promedio (k-means, muestra):", round(avg_sil_km, 4), "\n")
cat("Silhouette promedio (jerárquico, muestra):", round(avg_sil_hc, 4), "\n")

# Visualizar siluetas
factoextra::fviz_silhouette(sil_km) + ggtitle("Silueta - k-means (muestra)")
factoextra::fviz_silhouette(sil_hc) + ggtitle("Silueta - Jerárquico (muestra)")
```

```{r}
# Silueta kmeans (en la muestra jerárquica para comparar apples-to-apples)
km_sample_clusters <- km_fit$cluster[idx_hc]
sil_km <- cluster::silhouette(km_sample_clusters, d_hc)
avg_sil_km <- mean(sil_km[, 3])

# Silueta jerárquico (en la misma muestra)
sil_hc <- cluster::silhouette(hc_clusters, d_hc)
avg_sil_hc <- mean(sil_hc[, 3])

cat("Silhouette promedio (k-means, muestra):", round(avg_sil_km, 4), "\n")
cat("Silhouette promedio (jerárquico, muestra):", round(avg_sil_hc, 4), "\n")

# Visualizar siluetas
factoextra::fviz_silhouette(sil_km) + ggtitle("Silueta - k-means (muestra)")
factoextra::fviz_silhouette(sil_hc) + ggtitle("Silueta - Jerárquico (muestra)")
```
Con k = 7, la comparación entre k-means y clustering jerárquico en la misma muestra muestra que k-means logra una calidad global ligeramente superior, ya que su silueta promedio fue 0.6331 frente a 0.6204 del jerárquico. Esa diferencia es consistente con lo que se observa en los gráficos de silueta: en k-means la mayoría de observaciones mantienen valores positivos y cercanos o por encima de la línea promedio, mientras que en jerárquico aparecen más casos con silueta negativa (especialmente en un cluster con silueta promedio baja ~0.39), lo que indica asignaciones menos claras y mayor solapamiento entre algunos grupos.

A nivel de estructura de clusters, ambos métodos identifican al menos un grupo muy bien definido, lo cual sugiere que existe un segmento fuerte y consistente en los datos. Sin embargo, el jerárquico presenta un problema adicional: aparece un cluster de tamaño 1 con silueta promedio 0.00, lo que normalmente refleja un outlier o una separación artificial al cortar el dendrograma en k=7. Esto es importante porque, para segmentación práctica, no es deseable generar clusters extremadamente pequeños. En cambio, k-means produce tamaños más estables y evita ese “cluster singleton”, manteniendo grupos más utilizables para perfilado.

El dendrograma sí aporta una ventaja interpretativa: permite ver fusiones y posibles macrogrupos, útil si el objetivo fuera explorar segmentaciones en varios niveles. Pero dado que el objetivo del laboratorio es obtener una partición final e interpretable, y considerando la mejor silueta promedio, menos asignaciones negativas, y la ausencia de clusters degenerados, se selecciona k-means como el método principal para la interpretación final de clusters; el jerárquico se mantiene como referencia complementaria para validar que existe estructura y para explorar agrupamientos alternativos.

En esta sección se interpreta cada cluster perfilándolo con dos tipos de evidencia: variables numéricas (medias y medianas por cluster) para describir magnitud y desempeño, y  variables categóricas para identificar características comunes dentro de cada grupo . La idea es transformar la salida del algoritmo en segmentos “entendibles” y accionables para CineVision Studios: identificar grupos de películas con comportamiento similar, y así apoyar decisiones de catálogo, marketing o inversión.

```{r}
# --- 0) Asegurar objetos base ---
if(!exists("df")){
  if(exists("datos")) df <- datos else stop("No encuentro 'df' ni 'datos'.")
}
if(!exists("X")) stop("No encuentro la matriz 'X' (scaled) usada para clustering.")
if(!exists("k_star")) k_star <- 7  # por si ya definiste k=7 y no guardaste la variable

set.seed(123)
if(!exists("km_fit")){
  km_fit <- kmeans(X, centers = k_star, nstart = 50, iter.max = 200)
}

df_km <- df |> dplyr::mutate(cluster = factor(km_fit$cluster))

# --- 1) Resumen de tamaños por cluster ---
cluster_sizes <- df_km |> dplyr::count(cluster, name = "n") |> dplyr::arrange(cluster)
cluster_sizes

# --- 2) Perfil NUMÉRICO por cluster (media/mediana/sd) ---
# (usa solo numéricas reales presentes)
num_vars <- names(df_km)[sapply(df_km, is.numeric)]
num_vars <- setdiff(num_vars, c())  # por si quieres excluir algo luego

# Si quieres priorizar variables "clave", ponlas aquí (solo se usarán si existen)
key_vars_raw <- c("popularity","budget","revenue","runtime","voteCount","voteAvg",
                  "actorsPopularity","actorsAmount","castWomenAmount","castMenAmount",
                  "genresAmount","productionCoAmount","productionCountriesAmount","releaseYear")
key_vars <- intersect(key_vars_raw, num_vars)

# a) Tabla completa (puede ser grande)
num_profile <- df_km |>
  dplyr::group_by(cluster) |>
  dplyr::summarise(
    dplyr::across(
      dplyr::all_of(num_vars),
      list(
        mean = ~ mean(.x, na.rm = TRUE),
        median = ~ median(.x, na.rm = TRUE),
        sd = ~ sd(.x, na.rm = TRUE)
      ),
      .names = "{.col}_{.fn}"
    ),
    .groups = "drop"
  )

# b) Tabla compacta solo con variables clave (recomendada para describir clusters)
num_profile_key <- df_km |>
  dplyr::group_by(cluster) |>
  dplyr::summarise(
    dplyr::across(
      dplyr::all_of(key_vars),
      list(
        mean = ~ mean(.x, na.rm = TRUE),
        median = ~ median(.x, na.rm = TRUE)
      ),
      .names = "{.col}_{.fn}"
    ),
    n = dplyr::n(),
    .groups = "drop"
  ) |>
  dplyr::arrange(cluster)

num_profile_key

# --- 3) Perfil CATEGÓRICO por cluster (frecuencias y porcentajes) ---
cat_vars_all <- names(df_km)[sapply(df_km, function(x) is.character(x) || is.factor(x))]
cat_vars_all <- setdiff(cat_vars_all, "cluster")

# quedarnos con categóricas "manejables" (<=20 niveles) para que la tabla sea interpretable
cat_vars <- cat_vars_all[sapply(df_km[cat_vars_all], function(x) dplyr::n_distinct(x, na.rm = TRUE) <= 20)]
cat_vars

# Generar tablas por cada variable categórica (top categorías por cluster)
cat_tables <- list()

if(length(cat_vars) == 0){
  cat("No se detectaron variables categóricas de baja cardinalidad (<=20 niveles).\n")
} else {
  for(v in cat_vars){
    tab <- df_km |>
      dplyr::count(cluster, .data[[v]], name = "n") |>
      dplyr::group_by(cluster) |>
      dplyr::mutate(pct = n / sum(n)) |>
      dplyr::arrange(cluster, dplyr::desc(pct))
    
    # quedarnos con el top 3 por cluster para que sea más fácil escribir la interpretación
    tab_top3 <- tab |>
      dplyr::group_by(cluster) |>
      dplyr::slice_head(n = 3) |>
      dplyr::ungroup()
    
    cat_tables[[v]] <- tab_top3
  }
}

# Imprimir todas las tablas categóricas top 3 (si existen)
if(length(cat_tables) > 0){
  names(cat_tables)
  cat_tables
}
```

