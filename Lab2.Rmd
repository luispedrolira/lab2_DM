---
title: "Laboratorio 2"
author: "Luis Pedro Lira 23669, Mario Rocha 23501, Juan Francisco Martínez 23617"
date: "2025-02-07"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = F, warning = F)
```



```{r paquetes y datos, message=FALSE, warning=FALSE}

library(psych)
library(FactoMineR)
library(corrplot)
library(fpc)
library(factoextra)
library(PCAmixdata)
library(paran)
library(dplyr)
library(tidyverse)
library(janitor)
library(lubridate)
library(skimr)
library(clustertend)
library(cluster)

datos <- read.csv("movies_2026.csv", stringsAsFactors = FALSE)
```


###Análisis de Componentes Principales (PCA)

###3.1 Selección de Variables y Preprocesamiento

```{r}
# Selección de variables numéricas
vars_pca <- datos %>%
  select(popularity,
         budget,
         revenue,
         runtime,
         voteCount,
         voteAvg,
         actorsPopularity,
         actorsAmount,
         castWomenAmount,
         castMenAmount,
         genresAmount,
         productionCoAmount,
         productionCountriesAmount,
         releaseYear)

# Reemplazar strings vacíos por NA
vars_pca[vars_pca == ""] <- NA

# Convertir todo a numérico de forma segura
vars_pca <- data.frame(lapply(vars_pca, function(x) as.numeric(as.character(x))))

# Eliminar filas con NA
vars_pca <- na.omit(vars_pca)

# Verificar que todo sea numérico
str(vars_pca)

# Escalar
vars_scaled <- scale(vars_pca)
```

###3.2 Matriz de Correlación
```{r}
cor_matrix <- cor(vars_scaled)
corrplot(cor_matrix, method = "color")
```
En la matriz de correlación se observan asociaciones importantes entre varias variables del conjunto de datos. Destaca una correlación positiva entre budget y revenue, lo cual es consistente con la lógica de la industria cinematográfica: producciones con mayor presupuesto tienden a generar mayores ingresos.

También se observa relación entre voteCount, popularity y actorsPopularity, lo que sugiere que películas con mayor visibilidad tienden a recibir más votos.

Asimismo, existe alta correlación entre actorsAmount, castMenAmount y castWomenAmount, lo cual es esperado debido a que representan componentes del tamaño total del elenco.

Estas correlaciones evidencian redundancia entre variables, lo que justifica la aplicación del Análisis de Componentes Principales para reducir la dimensionalidad del conjunto de datos.




###3.3 Medida de Adecuación Muestral (Índice KMO)
```{r}
KMO(vars_scaled)
```

El índice KMO global obtenido fue de 0.69, lo cual indica una adecuación muestral aceptable para aplicar el Análisis de Componentes Principales.

Según la clasificación de Kaiser:
	•	0.90 → Excelente
	•	0.80 → Muy bueno
	•	0.70 → Bueno
	•	0.60 → Aceptable
	•	<0.50 → Inadecuado

En este caso, el valor se encuentra cercano a 0.70, lo que sugiere que las correlaciones parciales entre variables no son excesivamente altas y que el análisis factorial es apropiado, aunque no óptimo.





###3.4 Prueba de Esfericidad de Bartlett
```{r}
cortest.bartlett(cor_matrix, n = nrow(vars_scaled))
```
La prueba de esfericidad de Bartlett resultó altamente significativa (χ² = 5416.44, p < 0.001), lo que permite rechazar la hipótesis nula de que la matriz de correlación es una matriz identidad.

Esto confirma que existe correlación suficiente entre las variables y que el Análisis de Componentes Principales es apropiado para este conjunto de datos.



###3.5 Aplicación del Análisis de Componentes Principales
```{r}
pca_model <- prcomp(vars_scaled, center = TRUE, scale. = TRUE)

summary(pca_model)
```


##3.6 Determinación del Número de Componentes (Scree Plot y Varianza Explicada)
```{r}
fviz_eig(pca_model, addlabels = TRUE)
```

```{r}
eigenvalues <- pca_model$sdev^2
eigenvalues
```
El primer componente principal explica el 24.3% de la variabilidad total, seguido por el segundo con 12.6% y el tercero con 10.2%.

El gráfico de sedimentación muestra una disminución pronunciada después del tercer componente y una estabilización progresiva a partir del quinto componente.

Se decidió conservar los primeros 7 componentes, ya que explican aproximadamente el 74.7% de la variabilidad total, lo cual representa una reducción considerable de dimensionalidad manteniendo una proporción adecuada de información.




###3.7 Interpretación de los Componentes Principales
```{r}
loadings <- pca_model$rotation
round(loadings, 3)
```
```{r}
fviz_pca_biplot(pca_model, 
                repel = TRUE,
                col.var = "red",
                col.ind = "gray")
```
El primer componente parece representar una dimensión de impacto y visibilidad comercial, ya que agrupa variables relacionadas con popularidad, número de votos y popularidad del elenco.

La carga negativa en releaseYear sugiere que películas más antiguas tienden a tener mayor acumulación de popularidad y votos, lo cual puede deberse a mayor tiempo en el mercado.




###3.8 Conclusiones del PCA


El Análisis de Componentes Principales permitió reducir la dimensionalidad del conjunto de datos original compuesto por 14 variables numéricas, sintetizando la información en un menor número de componentes sin perder una proporción significativa de variabilidad.

Los primeros 7 componentes explican aproximadamente el 74.7% de la variabilidad total, lo cual representa una reducción considerable de la complejidad del dataset manteniendo la mayor parte de la información relevante.

El primer componente principal se asocia principalmente con variables relacionadas con popularidad, número de votos y popularidad del elenco, por lo que puede interpretarse como una dimensión de impacto y desempeño comercial.

El segundo componente está vinculado con la composición del elenco, diferenciando películas según la cantidad y distribución de actores.

El tercer componente refleja características estructurales de producción, como el número de compañías productoras y países involucrados, lo cual sugiere distintos niveles de complejidad en las producciones cinematográficas.

En conjunto, el PCA revela que las películas pueden caracterizarse principalmente a través de tres grandes dimensiones: impacto comercial, estructura del elenco y complejidad de producción.

Estos resultados son útiles para CineVision Studios, ya que permiten comprender cuáles factores explican mayor variabilidad en el mercado cinematográfico y pueden servir como base para futuros modelos predictivos o segmentaciones estratégicas.

```{r Seleccion de variables}
# Variables del PDF (posibles) incluyen: popularity, budget, revenue, runtime, vote_count, vote_avg,
# actors_popularity, genres_amount, production_co_amount, production_countries_amount,
# actors_amount, cast_women_amount, cast_men_amount, release_year, etc. :contentReference[oaicite:2]{index=2}

# 1) Variables típicamente NO útiles para formar grupos (IDs / texto libre / URLs / listas enormes):
vars_drop_if_exist <- c(
  "id", "original_title", "title", "homepage",
  "director", "actors", "actors_character",
  "production_company", "production_company_country",
  "production_country", "release_date"
)

df <- datos |> select(-any_of(vars_drop_if_exist))

# 2) Define con qué variables numéricas vas a calcular los grupos (ajusta si tu dataset difiere)
vars_num_raw <- c(
  "popularity", "budget", "revenue", "runtime",
  "vote_count", "vote_avg", "actors_popularity",
  "genres_amount", "production_co_amount", "production_countries_amount",
  "actors_amount", "cast_women_amount", "cast_men_amount",
  "release_year"
)

# Qué variables de esas realmente existen en tu df:
vars_num <- intersect(vars_num_raw, names(df))
vars_missing <- setdiff(vars_num_raw, names(df))

cat("Numéricas usadas para clustering:\n")
print(vars_num)
cat("\nNuméricas NO encontradas (si esperabas verlas, revisa nombres):\n")
print(vars_missing)

# Deja solo filas con al menos algunas variables disponibles
stopifnot(length(vars_num) >= 4)

df_num <- df |> select(all_of(vars_num))

# Asegurar numéricas (por si quedaron como character)
df_num <- df_num |> mutate(across(everything(), ~ suppressWarnings(as.numeric(.x))))

# Imputación simple: medianas por columna (rápido y estable para clustering)
impute_median <- function(x){
  ifelse(is.na(x), median(x, na.rm = TRUE), x)
}
df_num_imp <- df_num |> mutate(across(everything(), impute_median))

# Transformaciones para colas largas (muy típico en budget/revenue/vote_count/popularity)
vars_log1p <- intersect(c("budget", "revenue", "vote_count", "popularity", "actors_popularity"), vars_num)
df_num_tr <- df_num_imp |> mutate(across(all_of(vars_log1p), ~ log1p(pmax(.x, 0))))

# Estandarización (k-means y distancias lo necesitan)
X <- scale(df_num_tr)
X <- as.matrix(X)

cat("Dimensiones de X (filas, columnas):\n")
print(dim(X))
```

```{r Hopkins}

set.seed(123)

# Hopkins en muestra (rápido)
idx_hop <- sample(seq_len(nrow(X)), min(3000, nrow(X)))
X_hop <- X[idx_hop, , drop = FALSE]
n_hop <- min(200, floor(0.1 * nrow(X_hop)))

hop <- clustertend::hopkins(X_hop, n = n_hop)
hop
```

```{r Grafica de Codo}
k_max <- 12

# Codo (WSS) - requisito :contentReference[oaicite:4]{index=4}
factoextra::fviz_nbclust(X, kmeans, method = "wss", k.max = k_max) +
  ggtitle("Método del codo (WSS)")

# (Opcional pero útil) Silhouette vs k para apoyar tu decisión
factoextra::fviz_nbclust(X[sample(nrow(X), min(3000, nrow(X))), ], kmeans,
                         method = "silhouette", k.max = k_max) +
  ggtitle("Apoyo: Silhouette promedio vs k (muestra)")
```

```{r Elegir el K}
# Para que el flujo sea "óptimo" sin adivinar, elegimos k por silhouette promedio en muestra
# (y en el reporte justificas con el codo + esta evidencia).
n_k <- min(4000, nrow(X))
idx_k <- sample(seq_len(nrow(X)), n_k)
X_k <- X[idx_k, , drop = FALSE]

avg_sil_by_k <- function(k){
  km <- kmeans(X_k, centers = k, nstart = 30, iter.max = 100)
  d  <- dist(X_k)
  sil <- cluster::silhouette(km$cluster, d)
  mean(sil[, 3])
}

ks <- 2:k_max
sil_vals <- sapply(ks, avg_sil_by_k)

sil_tbl <- tibble(k = ks, avg_silhouette = sil_vals)
sil_tbl |> arrange(desc(avg_silhouette)) |> head(10)

k_star <- sil_tbl |> arrange(desc(avg_silhouette)) |> slice(1) |> pull(k)
cat("k elegido (por silhouette en muestra):", k_star, "\n")
```

```{r Agrupamiento}
# K-means en TODO el dataset
km_fit <- kmeans(X, centers = k_star, nstart = 50, iter.max = 200)

df_km <- df |> mutate(cluster_kmeans = factor(km_fit$cluster))

# Jerárquico: por complejidad O(n^2), lo hacemos en muestra (suficiente para comparar estructura)
n_hc <- min(3000, nrow(X))
idx_hc <- sample(seq_len(nrow(X)), n_hc)
X_hc <- X[idx_hc, , drop = FALSE]

d_hc <- dist(X_hc)
hc_fit <- hclust(d_hc, method = "ward.D2")
hc_clusters <- cutree(hc_fit, k = k_star)

df_hc <- df[idx_hc, ] |> mutate(cluster_hc = factor(hc_clusters))

# Dendrograma (opcional, puede ser grande)
plot(hc_fit, labels = FALSE, main = "Clustering jerárquico (Ward.D2) - muestra")
rect.hclust(hc_fit, k = k_star, border = 2:6)
```

```{r Silueta}
# Silueta kmeans (en la muestra jerárquica para comparar apples-to-apples)
km_sample_clusters <- km_fit$cluster[idx_hc]
sil_km <- cluster::silhouette(km_sample_clusters, d_hc)
avg_sil_km <- mean(sil_km[, 3])

# Silueta jerárquico (en la misma muestra)
sil_hc <- cluster::silhouette(hc_clusters, d_hc)
avg_sil_hc <- mean(sil_hc[, 3])

cat("Silhouette promedio (k-means, muestra):", round(avg_sil_km, 4), "\n")
cat("Silhouette promedio (jerárquico, muestra):", round(avg_sil_hc, 4), "\n")

# Visualizar siluetas
factoextra::fviz_silhouette(sil_km) + ggtitle("Silueta - k-means (muestra)")
factoextra::fviz_silhouette(sil_hc) + ggtitle("Silueta - Jerárquico (muestra)")
```
```{r}
# Silueta kmeans (en la muestra jerárquica para comparar apples-to-apples)
km_sample_clusters <- km_fit$cluster[idx_hc]
sil_km <- cluster::silhouette(km_sample_clusters, d_hc)
avg_sil_km <- mean(sil_km[, 3])

# Silueta jerárquico (en la misma muestra)
sil_hc <- cluster::silhouette(hc_clusters, d_hc)
avg_sil_hc <- mean(sil_hc[, 3])

cat("Silhouette promedio (k-means, muestra):", round(avg_sil_km, 4), "\n")
cat("Silhouette promedio (jerárquico, muestra):", round(avg_sil_hc, 4), "\n")

# Visualizar siluetas
factoextra::fviz_silhouette(sil_km) + ggtitle("Silueta - k-means (muestra)")
factoextra::fviz_silhouette(sil_hc) + ggtitle("Silueta - Jerárquico (muestra)")
```

